<<<<<<< HEAD
@INPROCEEDINGS{roma2013,
author={G. Roma and W. Nogueira and P. Herrera},
booktitle={2013 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics},
title={Recurrence quantification analysis features for environmental sound recognition},
year={2013},
pages={1-4},
keywords={audio signal processing;time series;RQA;auditory scene recognition;environmental audio recognition;environmental sound recognition;feature aggregation;nonlinear time series analysis technique;recurrence quantification analysis;unlabeled audio;Accuracy;Conferences;Databases;Feature extraction;Mel frequency cepstral coefficient;Time series analysis},
doi={10.1109/WASPAA.2013.6701890},
ISSN={1931-1168},
month={Oct},}

@inproceedings{bisot2016acoustic,
  title={Acoustic scene classification with matrix factorization for unsupervised feature learning},
  author={Bisot, Victor and Serizel, Romain and Essid, Slim and others},
  booktitle={2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={6445--6449},
  year={2016},
  organization={IEEE}
}

@inproceedings{giannoulis2013database,
  title={A database and challenge for acoustic scene classification and event detection},
  author={Giannoulis, Dimitrios and Stowell, Dan and Benetos, Emmanouil and Rossignol, Mathias and Lagrange, Mathieu and Plumbley, Mark D},
  booktitle={21st European Signal Processing Conference (EUSIPCO 2013)},
  pages={1--5},
  year={2013},
  organization={IEEE}
}

@article{lagrange:hal-01082501,
  TITLE = {{The bag-of-frames approach: a not so sufficient model for urban soundscapes}},
  AUTHOR = {Lagrange, Mathieu and Lafay, Gr{\'e}goire and Defreville, Boris and Aucouturier, Jean-Julien},
  URL = {https://hal.archives-ouvertes.fr/hal-01082501},
  JOURNAL = {{JASA Express Letters}},
  VOLUME = {138},
  NUMBER = {5},
  PAGES = {487-492},
  YEAR = {2015},
  MONTH = Oct,
  PDF = {https://hal.archives-ouvertes.fr/hal-01082501/file/lagrangeBof2014.pdf},
  HAL_ID = {hal-01082501},
  HAL_VERSION = {v2},
}

@ARTICLE{6847693,
author={B. L. Sturm},
journal={IEEE Transactions on Multimedia},
title={A Simple Method to Determine if a Music Information Retrieval System is a Horse},
year={2014},
volume={16},
number={6},
pages={1636-1644},
keywords={information retrieval systems;music;Clever Hans;FoM;MIR evaluation;MIR system;dataset ground truth;figure-of-merit;music information retrieval system;musical knowledge;Accuracy;Feature extraction;Multiple signal classification;Semantics;Silicon;Standards;Vocabulary;2-WORK system performance;5-CONT content description and annotation;5-SEAR multimedia search and retrieval},
doi={10.1109/TMM.2014.2330697},
ISSN={1520-9210},
month={Oct},}

@article{aucouturier2007bag,
  title={The bag-of-frames approach to audio pattern recognition: A sufficient model for urban soundscapes but not for polyphonic music},
  author={Aucouturier, Jean-Julien and Defreville, Boris and Pachet, Fran{\c{c}}ois},
  journal={The Journal of the Acoustical Society of America},
  volume={122},
  number={2},
  pages={881--891},
  year={2007},
  publisher={Acoustical Society of America}
}
@article{rakotomamonjy2015histogram,
  title={Histogram of gradients of time-frequency representations for audio scene classification},
  author={Rakotomamonjy, Alain and Gasso, Gilles},
  journal={IEEE/ACM Transactions on Audio, Speech and Language Processing (TASLP)},
  volume={23},
  number={1},
  pages={142--153},
  year={2015},
  publisher={IEEE Press}
}

=======
%% dataset
% dcase 2013
>>>>>>> origin/master
@ARTICLE{7100934,
author={D. Stowell and D. Giannoulis and E. Benetos and M. Lagrange and M. D. Plumbley},
journal={IEEE Transactions on Multimedia},
title={Detection and Classification of Acoustic Scenes and Events},
year={2015},
volume={17},
number={10},
pages={1733-1746},
doi={10.1109/TMM.2015.2428998},
ISSN={1520-9210},
month={Oct}
}

@inproceedings{giannoulis2013database,
  title={A database and challenge for acoustic scene classification and event detection},
  author={Giannoulis, Dimitrios and Stowell, Dan and Benetos, Emmanouil and Rossignol, Mathias and Lagrange, Mathieu and Plumbley, Mark D},
  booktitle={21st European Signal Processing Conference (EUSIPCO 2013)},
  pages={1--5},
  year={2013},
  organization={IEEE}
}

% dcase 2016
@InProceedings{Mesaros2016_EUSIPCO,
author      = {Mesaros, Annamaria and Heittola, Toni and Virtanen, Tuomas},
title       = {{TUT} Database for Acoustic Scene Classification and Sound Event Detection},
year        = 2016,
booktitle   = {24th European Signal Processing Conference 2016 (EUSIPCO 2016)},
address     = {Budapest, Hungary},
language    = {English}
}

%% PREVIOUS WORK
% DCASE 
@inproceedings{chum2013ieee,
  title={Scene classification challenge using hidden Markov models and frame based classification},
  author={Chum, May and Habshush, Ariel and Rahman, Abrar and Sang, Christopher},
  booktitle={IEEE Workshop on Applications of Signal Processing to Audio and Acoustics},
  year={2013},
organization={IEEE}
}

@inproceedings{elizalde2013vector,
  title={An i-vector based approach for audio scene detection},
  author={Elizalde, Benjamin and Lei, Howard and Friedland, Gerald and Peters, Nils},
  booktitle={IEEE Workshop on Applications of Signal Processing to Audio and Acoustics},
  year={2013},
organization={IEEE}
}

@inproceedings{geiger2013large,
  title={Large-scale audio feature extraction and SVM for acoustic scene classification},
  author={Geiger, J{\"u}rgen T and Schuller, Bj{\"o}rn and Rigoll, Gerhard},
  booktitle={IEEE Workshop on Applications of Signal Processing to Audio and Acoustics},
  year={2013},
  organization={IEEE}
}

@inproceedings{krijnders2013tone,
  title={A tone-fit feature representation for scene classification},
  author={Krijnders, Johannes D and ten Holt, GA},
  booktitle={IEEE Workshop on Applications of Signal Processing to Audio and Acoustics},
  year={2013},
  organization={IEEE}
}

@article{li2013auditory,
  title={Auditory scene classification using machine learning techniques},
  author={Li, David and Tam, Jason and Toub, Derek},
  booktitle={IEEE Workshop on Applications of Signal Processing to Audio and Acoustics},
  year={2013},
organization={IEEE}
}

@inproceedings{lee2013acoustic,
  title={Acoustic scene classification using sparse feature learning and event-based pooling},
  author={Lee, Kyogu and Hyung, Ziwon and Nam, Juhan},
  booktitle={IEEE Workshop on Applications of Signal Processing to Audio and Acoustics},
  year={2013},
  organization={IEEE}
}

@inproceedings{nogueira2013sound,
  title={Sound scene identification based on MFCC, binaural features and a support vector machine classifier},
  author={Nogueira, Waldo and Roma, Gerard and Herrera, Perfecto},
  booktitle={IEEE Workshop on Applications of Signal Processing to Audio and Acoustics},
  year={2013},
  organization={IEEE}
}

@inproceedings{olivetti2013wonder,
  title={The wonders of the normalized compression dissimilarity representation},
  author={Olivetti, Emanuele},
  booktitle={IEEE Workshop on Applications of Signal Processing to Audio and Acoustics},
  year={2013},
  organization={IEEE}
}

@inproceedings{patil2013multiresolution,
  title={Multiresolution auditory representations for scene classification},
  author={Olivetti, Emanuele},
  booktitle={IEEE Workshop on Applications of Signal Processing to Audio and Acoustics},
  year={2013},
  organization={IEEE}
}

@article{rakotomamonjy2015histogram,
  title={Histogram of gradients of time-frequency representations for audio scene classification},
  author={Rakotomamonjy, Alain and Gasso, Gilles},
  journal={IEEE/ACM Transactions on Audio, Speech and Language Processing (TASLP)},
  volume={23},
  number={1},
  pages={142--153},
  year={2015},
  publisher={IEEE Press}
}

@inproceedings{roma2013recurrence,
  title={Recurrence quantification analysis features for auditory scene classification},
  author={Roma, Gerard and Nogueira, Waldo and Herrera, Perfecto and de Boronat, Roc},
  booktitle={IEEE Workshop on Applications of Signal Processing to Audio and Acoustics},
  year={2013},
  organization={IEEE}
}

% other
@inproceedings{jiang2005svm,
  title={SVM-based audio scene classification},
  author={Jiang, Hongchen and Bai, Junmei and Zhang, Shuwu and Xu, Bo},
  booktitle={2005 International Conference on Natural Language Processing and Knowledge Engineering},
  pages={131--136},
  year={2005},
  organization={IEEE}
}

@inproceedings{kalinli2009saliency,
  title={Saliency-driven unstructured acoustic scene classification using latent perceptual indexing.},
  author={Kalinli, Ozlem and Sundaram, Shiva and Narayanan, Shrikanth S},
  booktitle={MMSP},
  volume={9},
  pages={5--7},
  year={2009}
}

@inproceedings{su2011environmental,
  title={Environmental sound classification for scene recognition using local discriminant bases and HMM},
  author={Su, Feng and Yang, Li and Lu, Tong and Wang, Gongyou},
  booktitle={Proceedings of the 19th ACM international conference on Multimedia},
  pages={1389--1392},
  year={2011},
  organization={ACM}
}


@article{barchiesi2015acoustic,
  title={Acoustic scene classification: Classifying environments from the sounds they produce},
  author={Barchiesi, Daniele and Giannoulis, Dimitrios and Stowell, Dan and Plumbley, Mark D},
  journal={IEEE Signal Processing Magazine},
  volume={32},
  number={3},
  pages={16--34},
  year={2015},
  publisher={IEEE}
}

@inproceedings{ye2015acoustic,
  title={Acoustic Scene Classification based on Sound Textures and Events},
  author={Ye, Jiaxing and Kobayashi, Takumi and Murakawa, Masahiro and Higuchi, Tetsuya},
  booktitle={Proceedings of the 23rd ACM international conference on Multimedia},
  pages={1291--1294},
  year={2015},
  organization={ACM}
}

@inproceedings{bisot2015hog,
  title={HOG and subband power distribution image features for acoustic scene classification},
  author={Bisot, Victor and Essid, Slim and Richard, Ga{\"e}l},
  booktitle={Signal Processing Conference (EUSIPCO), 2015 23rd European},
  pages={719--723},
  year={2015},
  organization={IEEE}
}

@inproceedings{chakrabarty2015exploring,
  title={Exploring the role of temporal dynamics in acoustic scene classification},
  author={Chakrabarty, Debmalya and Elhilali, Mounya},
  booktitle={Applications of Signal Processing to Audio and Acoustics (WASPAA), 2015 IEEE Workshop on},
  pages={1--5},
  year={2015},
  organization={IEEE}
}

@inproceedings{xue2015auditory,
  title={Auditory scene classification with deep belief network},
  author={Xue, Like and Su, Feng},
  booktitle={International Conference on Multimedia Modeling},
  pages={348--359},
  year={2015},
  organization={Springer}
}


@inproceedings{bisot2016acoustic,
  title={Acoustic scene classification with matrix factorization for unsupervised feature learning},
  author={Bisot, Victor and Serizel, Romain and Essid, Slim and others},
  booktitle={2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={6445--6449},
  year={2016},
  organization={IEEE}
}

% bag of frame
@article{aucouturier2007bag,
  title={The bag-of-frames approach to audio pattern recognition: A sufficient model for urban soundscapes but not for polyphonic music},
  author={Aucouturier, Jean-Julien and Defreville, Boris and Pachet, Fran{\c{c}}ois},
  journal={The Journal of the Acoustical Society of America},
  volume={122},
  number={2},
  pages={881--891},
  year={2007},
  publisher={Acoustical Society of America}
}

@article{lagrange:hal-01082501,
  TITLE = {{The bag-of-frames approach: a not so sufficient model for urban soundscapes}},
  AUTHOR = {Lagrange, Mathieu and Lafay, Gr{\'e}goire and Defreville, Boris and Aucouturier, Jean-Julien},
  URL = {https://hal.archives-ouvertes.fr/hal-01082501},
  JOURNAL = {{JASA Express Letters}},
  VOLUME = {138},
  NUMBER = {5},
  PAGES = {487-492},
  YEAR = {2015},
  MONTH = Oct,
  PDF = {https://hal.archives-ouvertes.fr/hal-01082501/file/lagrangeBof2014.pdf},
  HAL_ID = {hal-01082501},
  HAL_VERSION = {v2},
}

%% MOTIVATION/INTRODUCTION (psycho, neuro)

% psycho
@inproceedings{lafaySoundscapePilot,
 author = {Gregoire Lafay and Mathias Rossignol and Nicolas Misdariis and Mathieu Lagrange and Jean-Francois Petiot},
 title = {A new experimental approach for urban soundscape characterization based on sound manipulation : A pilot study},
 booktitle = {Proceedings of the 26th International Symposium on Musical Acoustics},
 year = {2014},
}


@unpublished{lafayPartI,
  TITLE = {Investigating soundscapes perception through acoustic scenes simulation. Part I: simulation protocol presentation and case study},
  AUTHOR = {Lafay, Gr{\'e}goire and Misdariis, Nicolas and Lagrange, Mathieu and Rossignol, Mathias},
  NOTE = {under revision},
  YEAR = {2016},
  MONTH = Apr
}

@inproceedings{guyot2005urban,
  title={Urban sound environment quality through a physical and perceptive classification of sound sources: a cross-cultural study},
  author={Guyot, F and Nathanail, C and Montignies, F and Masson, B},
  booktitle={Proceedings Forum Acusticum, Budapest, Hungary},
  year={2005}
}

@article{ricciardi2015sound,
  title={Sound quality indicators for urban places in Paris cross-validated by Milan data},
  author={Ricciardi, Paola and Delaitre, Pauline and Lavandier, Catherine and Torchia, Francesca and Aumond, Pierre},
  journal={The Journal of the Acoustical Society of America},
  volume={138},
  number={4},
  pages={2337--2348},
  year={2015},
  publisher={Acoustical Society of America}
}

@article{dubois2006cognitive,
  title={A cognitive approach to urban soundscapes: Using verbal data to access everyday life auditory categories},
  author={Dubois, Dani{\`e}le and Guastavino, Catherine and Raimbault, Manon},
  journal={Acta Acustica united with Acustica},
  volume={92},
  number={6},
  pages={865--874},
  year={2006},
  publisher={S. Hirzel Verlag}
}

@article{maffiolo_caracterisation_1999,
  title={De la caract{\'e}risation s{\'e}mantique et acoustique de la qualit{\'e} sonore de l’environnement urbain},
  author={Maffiolo, Val{\'e}rie},
  journal={Semantic and acoustic characterization of urban environmental sound quality") Ph. D. dissertation, Universit{\'e} du Maine, France},
  year={1999}
}

@article{guastavino_ideal_2006,
    title = {The ideal urban soundscape: Investigatng the sound quality of french cities},
    volume = {92},
    journal = {Acta Acustica United with Acustica},
    author = {Guastavino, Catherine},
    year = {2006},
    keywords = {{VP}},
    pages = {945--951},
    file = {Guastavino2006_Ideal_Urban_Soundscape_French_cities.pdf:C:\Users\LAFAY\AppData\Roaming\Zotero\Zotero\Profiles\f3yp208b.default\zotero\storage\7IHQQAEU\Guastavino2006_Ideal_Urban_Soundscape_French_cities.pdf:application/pdf}
}

% ecoacoustic
@inproceedings{ECOACOUSTICS2014,
title = {Ecology and acoustics: emergent properties from community to landscape},
year = {2014},
organization = {Sueur, J. and Farina, A. and Bobryk, C. and Llusia, D. and McWilliam, J. and Pieretti, N.},
publisher = {Muséum national d'Histoire naturelle},
address = {Paris, France},
month = {June},
pages = {94},
url = {http://ecoacoustics.sciencesconf.org/},
}


@article{krause,
year={2011},
issn={0921-2973},
journal={Landscape Ecology},
volume={26},
number={9},
doi={10.1007/s10980-011-9600-8},
title={What is soundscape ecology? An introduction and overview of an emerging new science},
url={http://dx.doi.org/10.1007/s10980-011-9600-8},
publisher={Springer Netherlands},
keywords={Soundscape ecology; Landscape ecology; Bioacoustics; Soundscape conservation; Acoustic ecology; Biophony; Geophony; Anthrophony; Land use change; Climate change},
author={Pijanowski, Bryan C. and Farina, Almo and Gage, StuartH. and Dumyahn, SarahL. and Krause, Bernie L.},
pages={1213-1232},
language={English}
}

@article{stowell13a,
  author  = {Dan Stowell and Mark D. Plumbley},
  title   = {Segregating Event Streams and Noise with a Markov Renewal Process Model},
  journal = {Journal of Machine Learning Research},
  year    = {2013},
  volume  = {14},
  pages   = {2213-2238},
  url     = {http://jmlr.org/papers/v14/stowell13a.html}
}

@article{stowell13b,
  author  = {Dan Stowell and Mark D. Plumbley},
  title   = {Large-scale analysis of frequency modulation in birdsong databases},
  journal = {Methods in Ecology and Evolution},
  year    = {2013},
  volume  = {11},
}

@article{NessSST13,
  author = {Ness, Steven R. and Symonds, Helena and Spong, Paul and Tzanetakis, George},
   ee = {http://arxiv.org/abs/1307.0589},
  interhash = {ed7b7acd89dd6fbf8a72822a8d3fa3bd},
  intrahash = {483913a3e840c8f7caa4787d54bdbe48},
  journal = {International Workshop on Machine Learning for Bioacoustics},
  keywords = {dblp},
  timestamp = {2013-08-15T00:00:00.000+0200},
  title = {The Orchive : Data mining a massive bioacoustic archive.},
  year = 2013
}


%% SCATTERING

@book{Fastl2007,
abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-$\alpha$-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 {\AA} for the interface backbone atoms) increased from 21{\%} with default Glide SP settings to 58{\%} with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63{\%} success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40{\%} of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Fastl, Hugo and Zwicker, Eberhard},
booktitle = {Psychoacoustics: Facts and Models},
doi = {10.1007/978-3-540-68888-4},
eprint = {arXiv:1011.1669v3},
isbn = {3540231595},
issn = {1098-6596},
pages = {1--463},
pmid = {25246403},
title = {{Psychoacoustics: Facts and models, chapter 4}},
url = {http://zhenilo.narod.ru/new{\_}main/students/Zwicker{\_}Fastl.pdf},
year = {2007}
}

@article{Mallat2012,
abstract = {Pattern classification often requires using translation invariant representations, which are stable and hence Lipschitz continuous to deformations. A Fourier transform does not provide such Lipschitz stability. Scattering operators are obtained by iterating on wavelet transforms and modulus operators. The resulting representation is proved to be translation invariant and Lipschitz continuous to deformations, up to a log term. It is computed with a non-linear convolution network, which scatters functions along an infinite set of paths. Invariance to the action of any compact Lie subgroup of the general linear group is obtained with a combined scattering, which iterates over wavelet transforms defined on this group. Scattering representations yield new metrics on stationary processes, which are stable to random deformations.},
archivePrefix = {arXiv},
arxivId = {1101.2286},
author = {Mallat, St{\'{e}}phane},
doi = {10.1002/cpa.21413},
eprint = {1101.2286},
issn = {00103640},
journal = {Communications on Pure and Applied Mathematics},
number = {10},
pages = {1331--1398},
title = {{Group Invariant Scattering}},
url = {http://www.cmap.polytechnique.fr/{~}mallat/papiers/ScatCPAM.pdf},
volume = {65},
year = {2012}
}


@inproceedings{Anden2015,
author={J. And\'en and V. Lostanlen and S. Mallat},
booktitle={2015 IEEE 25th International Workshop on Machine Learning for Signal Processing (MLSP)},
title={Joint time-frequency scattering for audio classification},
year={2015},
pages={1-6},
abstract={We introduce the joint time-frequency scattering transform, a time shift invariant descriptor of time-frequency structure for audio classification. It is obtained by applying a two-dimensional wavelet transform in time and log-frequency to a time-frequency wavelet scalogram. We show that this descriptor successfully characterizes complex time-frequency phenomena such as time-varying filters and frequency modulated excitations. State-of-the-art results are achieved for signal reconstruction and phone segment classification on the TIMIT dataset.},
keywords={audio signal processing;frequency modulation;signal classification;signal reconstruction;time-frequency analysis;time-varying filters;wavelet transforms;TIMIT dataset;audio classification;complex time-frequency phenomena;frequency modulated excitations;joint time-frequency scattering transform;phone segment classification;signal reconstruction;time shift invariant descriptor;time-frequency structure;time-frequency wavelet scalogram;time-varying filters;two-dimensional wavelet transform;Convolution;Frequency modulation;Joints;Scattering;Time-frequency analysis;Wavelet transforms;audio classification;convolutional networks;invariant descriptors;time-frequency structure;wavelets},
doi={10.1109/MLSP.2015.7324385},
ISSN={1551-2541},
month={Sept},}

@article{Anden2014,
  title={Deep scattering spectrum},
  author={And{\'e}n, Joakim and Mallat, St{\'e}phane},
  journal={IEEE Transactions on Signal Processing},
  volume={62},
  number={16},
  pages={4114--4128},
  year={2014},
  publisher={IEEE}
}

@article{Joder2009,
abstract = {Nowadays, it appears essential to design automatic indexing tools which provide meaningful and efficient means to describe the musical audio content. There is in fact a growing interest for music information retrieval (MIR) applications amongst which the most popular are related to music similarity retrieval, artist identification, musical genre or instrument recognition. Current MIR-related classification systems usually do not take into account the mid-term temporal properties of the signal (over several frames) and lie on the assumption that the observations of the features in different frames are statistically independent. The aim of this paper is to demonstrate the usefulness of the information carried by the evolution of these characteristics over time. To that purpose, we propose a number of methods for early and late temporal integration and provide an in-depth experimental study on their interest for the task of musical instrument recognition on solo musical phrases. In particular, the impact of the time horizon over which the temporal integration is performed will be assessed both for fixed and variable frame length analysis. Also, a number of proposed alignment kernels will be used for late temporal integration. For all experiments, the results are compared to a state of the art musical instrument recognition system.},
author = {Joder, Cyril and Essid, Slim and Richard, Ga{\"{e}}l},
doi = {10.1109/TASL.2008.2007613},
file = {:Users/vlostan/Documents/Mendeley Desktop/Joder, Essid, Richard - 2009 - Temporal integration for audio classification with application to musical instrument classification.pdf:pdf},
issn = {15587916},
journal = {IEEE Transactions on Audio, Speech and Language Processing},
keywords = {Alignment kernels,Audio classification,Music information retrieval (MIR),Musical instrument recognition,Support vector machine (SVM),Temporal feature integration},
number = {1},
pages = {174--186},
title = {{Temporal integration for audio classification with application to musical instrument classification}},
url = {http://biblio.telecom-paristech.fr/cgi-bin/download.cgi?id=8585},
volume = {17},
year = {2009}
}
